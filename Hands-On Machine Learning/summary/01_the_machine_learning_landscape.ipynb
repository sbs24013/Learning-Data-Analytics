{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 한눈에 보는 머신러닝\n",
    "\n",
    "## 1.1 머신러닝이란?\n",
    "\n",
    "데이터에서 학습하도록 컴퓨터를 프로그래밍하는 과학(또는 예술)\n",
    "\n",
    "일반적인 정의: 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게하는 연구 분야\n",
    "\n",
    "공학적인 정의: 어떤 작업 T에 대한 컴퓨터 프로그래밍의 성능을 P로 측정했을 때 경험 E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 P에 대해 경험 E로 학습한 것이다.\n",
    "\n",
    "훈련 세트: 시스템이 학습하는 데 사용하는 샘플\n",
    "\n",
    "훈련 사례(샘플): 각각의 훈련 데이터\n",
    "\n",
    "모델: 머신러닝 시스템에서 학습하고 예측을 만드는 부분\n",
    "- 예: 신경망, 랜덤포레스트\n",
    "\n",
    "\n",
    "## 1.2 왜 머신러닝을 사용하나요?\n",
    "\n",
    "- 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제\n",
    "- 전통적인 방식으로는 해결 방법이 없는 복잡한 문제\n",
    "- 유동적인 환경: 새로운 데이터로 쉽게 재훈련할 수 있어 항상 최신 상태를 유지한다\n",
    "- 복잡한 문제와 대량의 데이터에서 인사이트 얻기 (데이터 마이닝)\n",
    "\n",
    "## 1.3 애플리케이션 사례\n",
    "\n",
    "## 1.4 머신러닝 시스템의 종류\n",
    "\n",
    "- 훈련 지도 방식(지도, 비지도, 준지도, 자기 지도, 강화 학습)\n",
    "- 실시간으로 점진적인 합습을 하는지 아닌지(온라인 학습과 배치 학습)\n",
    "- 사례 기반 학습과 모델 기반 학습\n",
    "\n",
    "### 1.4.1 훈련 지도 방식\n",
    "\n",
    "머신러닝 시스템을 **학습하는 동안의 지도 형태나 정보량**에 따라 분류할 수 있다\n",
    "\n",
    "**지도 학습**\n",
    "- 알고리즘에 주입하는 훈련 데이터에 **레이블**이라는 답이 포함된다\n",
    "- **분류(classifications)**: ex. 스팸 필터\n",
    "- **회귀(regression**): **특성(features)**을 사용해 **타깃(target)** 수치를 예측하는 것\n",
    "\n",
    "타깃(분류에서 많이 사용) = 레이블(회귀에서 많이 사용)\n",
    "\n",
    "특성 = 예측 변수(prediction) = 속성(attribute)\n",
    "\n",
    "일부 분류 알고리즘은 회귀에 사용할 수 있다: \n",
    "- ex. 로지스틱 회귀: 클래스에 속할 확률을 출력한다\n",
    "\n",
    "**비지도 학습**\n",
    "\n",
    "- 군집 알고리즘: ex. 알고리즘 스스로 방문자 사이의 연결고리를 찾는다.\n",
    "- 계층 군집 알고리즘: ex. 블로그에 방문하는 방문자의 그룹을 더 작은 그룹으로 세분화할 수 있다. \n",
    "- 시각화 알고리즘: 레이블이 없는 대규묘의 고차원 데이터를 넣으면 도식화 가능한 2D나 3D 표현을 만들어 준다.\n",
    "- 차원 축소: 너무 많은 정보를 잃기 않으면서 데이터를 간소화 (특성추출: 상관관계가 있는 특성을 하나로 합친다)\n",
    "- 이상치 탐지(outliner detection): 이상치를 학습 알고리즘에 주입하기 전에 데이터셋에서 자동으로 제거\n",
    "- 특이치 탐지(novelty detection): 훈련 세트에 있는 모든 샘플과 달라 보이는 샘플을 탐지하는 것\n",
    "- 연관 규칙 학습(association rule learning): 대량의 데이터에서 특성 간의 흥미로운 관계를 찾는 알고리즘\n",
    "\n",
    "**준지도 학습**\n",
    "- 레이블이 일부만 있는 데이터를 다루는 알고리즘\n",
    "- 지도 학습과 비지도 학습의 조합으로 이루어져 있다\n",
    "- ex. 군집 알고리즘을 사용해서 비슷한 샘플을 하나의 그룹으로 모으고, 레이블이 없는 샘플에 클러스터에서 가장 많이 등장하는 레이블을 할당한다. 전체 데이터셋에 레이블이 부여되고 나면 지도 학습 알고리즘을 사용할 수 있다.\n",
    "\n",
    "**자기 지도 학습(self-supervised learning)**\n",
    "- 레이블이 전혀 없는 데이터셋에 레이블이 완전히 부여된 데이터셋을 생성하는 것\n",
    "- 전체 데이터셋에 레이블이 부여되고 나면 지도 학습 알고리즘을 사용할 수 있다. \n",
    "- 학습하는 동안 (생성된) 레이블을 사용하기 때문에 \"지도 학습\"에 더 가깝다\n",
    "\n",
    "전이 학습(transfer learning): 한 작업에서 다른 작업으로 지식을 전달하는 것\n",
    "\n",
    "**강화 학습(reinforcement learning)**\n",
    "- 에이전트: 학습하는 시스템\n",
    "- \"환경\"을 관찰해서 \"행동\"을 실행하고 그 결과로 \"보상 (또는 벌점)\"을 받는다. \n",
    "- 시간이 지나면서 가장 큰 보상을 얻기 위해 \"정책\"이라고 부르는 최상의 전략을 스스로 학습한다.\n",
    "- 정책: 주어진 상황에서 에이전트가 어떤 행동을 선택해야 할지 정의 한다.\n",
    "- ex. 딥마인드의 알파고 프로그램\n",
    "- 오프라인 학습: 학습 기능을 끄고 그동한 학습했던 전략을 적용\n",
    "\n",
    "### 1.4.2 배치 학습과 온라인 학습\n",
    "\n",
    "입력 데이터의 스트림으로부터 점진적으로 학습할 수 있는지 여부\n",
    "\n",
    "**배치 학습(batch learning)**\n",
    "- 시스템이 점진적으로 학습할 수 없다\n",
    "- 가용한 데이터를 모두 사용해 훈련을 시키고, 룬현 시킨 다음 제품 시스템에 적용하면 더 이상의 학습 없이 실행된다. (오프라인 학습)\n",
    "- 모델 부패(model rot) = 데이터 드리프트(data draft): 모델의 성능이 시간이 지남에 따라 감소\n",
    "- 성능이 저하된 경우, 새로운 데이터를 포함한 전체 데이터를 사용하여 훈련 한 후, 이전 모델을 새 모델로 교체할 수 있다.\n",
    "- 시스템이 빠르게 변하는 데이터에 적응해야 한다면, 데이터의 양이 아주 많으면, 자원이 제한된 시스템이 스스로 학습해야 한다면 \"점진적으로 학습할 수 있는 알고르짐\"을 사용하는 것이 낫다\n",
    "\n",
    "**온라인 학습(online learning)**\n",
    "- 데이터를 순차적으로 한 개씩 도는 \"미니배치\"라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련시킨다.\n",
    "- = 외부 메모리 학습(out-of-core learning): 아주 큰 데이터셋에서 모델을 훈련할 수 있다. \n",
    "- = 점진적 학습(incremental learning): 외부 메모리 학습은 보통 오프라인으로 실행된다. (실시간 수행X)\n",
    "- 학습률(learning-rate) 파라미터: 변화하는 데이터에 얼마나 빠르게 적응할 것 인지\n",
    "- 시스템에 나쁜 데이터가 주입되었을 때 시스템 성능이 감소 할 위험이 있다. 시스템을 면밀히 모니터링해서 성능 감소가 감지되면 즉각 학습을 중지시켜야 한다.\n",
    "\n",
    "### 1.4.3 사례 기반 학습과 모델 기반 학습\n",
    "\n",
    "모델은 훈련 데이터에 높은 성능을 낼 뿐만 아니라, 새로운 샘플을 잘 예측해야 한다. (일반화; generalization)\n",
    "\n",
    "**사례 기반 학습(instance-based learning)**\n",
    "- 시스템이 훈련 샘플을 기억함으로써 학습하고,\n",
    "- 유사도 측정을 사용해 새로운 데이터와 학습한 샘픔을 비교하는 식으로 일반화한다.\n",
    "\n",
    "\n",
    "**모델 기반 학습(model-based learning)**\n",
    "- 모델을 만들어 예측에 사용하는 것\n",
    "- 모델 선택: \"1인당 GDP\"라는 특성 하나를 가진 삶의 만족도에 대한 \"선형 모델\"\n",
    "- 모델 파라미터: 모델 파라미터를 조정하여 선형 함수를 표현하는 모델을 얻을 수 있다.\n",
    "- 측정 지표\n",
    "  - 효용 함수(utility function) = 적합도 함수(fitness function): 모델이 얼마나 좋은지 측정\n",
    "  - 비용 함수(cost function): 얼마나 나쁜지 측정\n",
    "  - 선형 회귀에서는 보통 선형 모델의 예측과 훈련 데이터 사이의 거리를 재는 비용함수를 사용한다.\n",
    "- 훈련: 알고리즘에 훈련 데이터를 공급하면 데이터에 가장 잘 맞는 선형 모델의 파라미터를 찾는다\n",
    "\n",
    "\n",
    "작업 요약\n",
    "1. 데이터를 분석한다\n",
    "2. 모델을 선택한다\n",
    "3. 훈련 데이터로 모델을 훈련시킨다 (학습 알고리즘이 비용 함수를 최소화하는 모델 파라미터를 찾는다)\n",
    "4. 새로운 데이터에 모델을 적용해 예측을 만든다 (추론; inference)\n",
    "\n",
    "## 1.5 머신러닝의 주요 도전 과제\n",
    "\n",
    "### 1.5.1 충분하지 않은 양의 훈련 데이터\n",
    "\n",
    "대부분의 머신러닝 알고리즘이 잘 작동하려면 데이터가 많아야 한다\n",
    "\n",
    "### 1.5.2 대표성 없는 훈련 데이터\n",
    "\n",
    "일반화가 잘되기 위해서는 훈련 데이터가 일반화하고 싶은 새로운 사례를 잘 대표하는 것이 중요하다\n",
    "\n",
    "샘플이 작으면 샘플링 잡음(sampling noise; 우연에 의한 대표성 없는 데이터)이 생기고, \n",
    "매우 큰 샘플도 표본 추출 방법이 잘못되면 대표성을 끠지 못할 수 있다. (샘플링 편향; sampling bias)\n",
    "\n",
    "### 1.5.3 낮은 품질의 데이터\n",
    "\n",
    "훈련 데이터 정제가 필요한 경우\n",
    "- 일부 샘플이 이상치라는 게 명확하면 간단히 해당 샘플들을 무시하거나 수동으로 잘못된 것을 고치는 것이 좋다\n",
    "- 일부 샘플에 특성 몇개가 빠졋다면 이 특성을 모두 무시할지, 이 샘플을 무시할지, 빠진 값을 채울지, 또는 이 특성을 넣은 모델과 제외한 모델로 따로 훈련시킬 것인지 결정해야 한다\n",
    "\n",
    "### 1.5.4 관련 없는 특성\n",
    "\n",
    "특성 공학: 훈련에 사용할 좋은 특성들을 찾는 것\n",
    "- 특성 선택: 가지고 있는 특성 중 훈련에 가장 유용한 특성을 선택한다\n",
    "- 특성 추출: 특성을 결합하여 더 유용한 특성을 만든다\n",
    "- 데이터 수집: 새로운 데이터를 수집해 새 특성을 만든다\n",
    "\n",
    "### 1.5.5 훈련 데이터 과대적합(overfitting)\n",
    "\n",
    "모델이 훈련 데이터에는 너무 잘 맞지만 일반성이 떨어지는 것\n",
    "\n",
    "과대적합은 훈련 데이터의 양과 잡음에 비해 모델이 너무 복잡할 때 일어난다\n",
    "\n",
    "해결 방법\n",
    "- 파라미터 수가 적은 모델을 선택하거나, 훈련 데이터에 있는 특성 수를 줄이거나, 모델에 제약을 가해서 단순화 시킨다\n",
    "- 훈련 데이터를 더 많이 모은다\n",
    "- 훈련 데이터의 잡음을 줄인다. (오류 데이터 수정과 이상치 제거)\n",
    "\n",
    "규제(regularization)\n",
    "- 모델을 단순하게 하고 과대적합의 위험을 줄이기 위해 모델에 제약을 가하는 것\n",
    "- 하이퍼파라미터:\n",
    "  - 학습하는 동안 적용한 규제의 양\n",
    "  - 학습 알고리즘의 파라미터\n",
    "  - 규제 하이퍼 파라미터를 매우 큰 값으로 지정하면 훈련 데이터에 과대적합될 가능성은 거의 없지만 좋은 모델을 찾지 못한다.\n",
    "\n",
    "### 1.5.6 훈련 데이터의 과소적합(underfitting)\n",
    "\n",
    "모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 일어난다\n",
    "\n",
    "해결 방법\n",
    "- 모델 파라미터가 더 많은 강력한 모델을 선택한다\n",
    "- 학습 알고리즘에 더 좋은 특성을 제공한다(특성 공학)\n",
    "- 모델의 제약을 줄인다\n",
    "\n",
    "### 1.5.7 핵심 요약\n",
    "\n",
    "- 머신러닝은 명시적인 규칙을 코딩하지 않고 기계가 데이터로부터 학습하여 어떤 작업을 더 잘하도록 만드는 것\n",
    "- 종류: 지도 학습과 비지도 학습, 배치 학습과 온라인 학습, 사례 기반 학습과 모델 기반 학습\n",
    "- 머신러닝 프로젝트에서는 훈련 세트에 데이터를 모아 학습 알고리즘에 주입한다.\n",
    "  - 모델 기반: (회귀) 훈련 세트에 모델을 맞추기 위해 모델 파라미터를 조정\n",
    "  - 사례 기반: (분류) 샘플을 기억하여 유사도 측정을 사용하여 학습된 샘플과 새로운 샘플을 비교\n",
    "- 훈련 세트가 너무 작거나, 대표성이 없거나, 잡음이 많고 관련없는 특성으로 오염되어 있다면 시스템이 잘 작동되지 않는다. \n",
    "- 모델이 너무 단순하거나(과소적합) 너무 복잡하지 않아야 한다(과대적합)\n",
    "\n",
    "### 1.6 테스트와 검증\n",
    "\n",
    "훈련 데이터를 \"훈련 세트\"와 \"테스트 세트\"로 나누어 모델을 훈련하고 테스트한다.\n",
    "\n",
    "새로운 샘플에 대한 오차 비율: 일반화 오차(generalization error), 외부 샘플 오차(out-of-sample error)\n",
    "\n",
    "테스트 세트에서 모델을 평가함으로써 이 오차에 대한 추정값을 얻는다.\n",
    "\n",
    "훈련 오차가 작지만, 일반화 오차가 크다면 이는 모델이 훈련 데이터에 과대적합되었다는 뜻이다.\n",
    "\n",
    "### 1.6.1 하이퍼파라미터 튜닝과 모델 선택\n",
    "\n",
    "홀드아웃 검증(holdout validation)\n",
    "- 훈련 세트의 일부를 떼어내어 여러 후보 모델을 평가하고 가장 좋은 하나를 선택\n",
    "- 검증 세트(validation set): 새로운 홀드 아웃 세트 = 개발 세트(development set; dev set)\n",
    "- 훈련 세트에서 다양한 하이퍼파라미터 값을 가진 여러 모델을 훈련하고, 검증 세트에서 가장 높은 성능을 내는 모델을 선택한다.\n",
    "- 검증이 끝나면 전체 훈련 세트에서 다시 훈련하여 최종 모델을 만든다.\n",
    "\n",
    "교차 검증\n",
    "- 작은 검증 세트를 여러 개를 사용해 반복적인 교차 검증을 수행\n",
    "- 단점: 훈련 시간이 검증 세트의 개수에 비례해 늘어난다\n",
    "\n",
    "### 1.6.2 데이터 불일치\n",
    "\n",
    "어떤 경우에는 쉽게 많은 양의 훈련 데이터를 얻을 수 있지만 이 데이터가 실제 제품이 사용될 데이터를 완벽하게 대표하지 못할 수 있다. \n",
    "\n",
    "검증 세트와 테스트 세트가 실전에서 기대하는 데이터를 가능한 잘 대표해야 한다.\n",
    "\n",
    "훈련 세트 -> 훈련-개발 세트 (평가) -> 검증 세트 (평가) -> 테스트 세트\n",
    "- 훈련-개발 세트 평가 성능이 낮은 경우: 모델을 규제하거나, 더 많은 훈련 데이터를 모으거나 훈련 데이터 정제를 시도\n",
    "- 검증 세트 성능이 낮은 경우: 데이터 불일치, 데이터 불일치를 해소 할 수 있도록 데이터 전처리가 필요하다\n",
    "\n",
    "공짜 점심 없음 이론(no free lunch)\n",
    "- 데이터에 관해 완벽하게 아무런 가정도 하지 않으면 한 모델을 다른 모델보다 선호할 근거가 없음\n",
    "- \"경험하기 전에\" 더 맞을 거라고 보장할 수 있는 모델은 없다\n",
    "- 모든 모델을 평가하여 최선의 모델을 찾아야 한다\n",
    "  - 실전에서는, 데이터에 관해 타당한 가정을 하고 적잘한 모델 몇 가지만 평가한다.\n",
    "    - 간단한 작업: 규제의 수준이 다양한 선형 모델\n",
    "    - 복잡한 문제: 여러가지 신경망을 평가\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
